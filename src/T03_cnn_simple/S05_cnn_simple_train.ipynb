{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd55ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pt_runner.cnn import CheckpointHandler, DataHandlerPT, EarlyStopper, calc_metrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New run\n",
    "NEW_RUN = True\n",
    "DT_REF = None\n",
    "\n",
    "# Resuming\n",
    "# NEW_RUN = False\n",
    "# DT_REF = \"2025-05-28_12-35\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mnist_small.pickle\", \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = data[\"_X\"].astype(np.float64)\n",
    "_Y = data[\"_Y\"].astype(np.int32)\n",
    "print(_X.shape)\n",
    "print(_X.dtype)\n",
    "print(_Y.shape)\n",
    "print(_Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_handler = DataHandlerPT(_X=_X, _Y=_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f511d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((4, 4))\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.max_pool(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.max_pool(X)\n",
    "        X = self.adaptive_pool(X)\n",
    "        X = X.view(X.shape[0], -1)\n",
    "        X = self.fc1(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "model = SimpleCNN(num_classes=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=5)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302994cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "input_size = (100, 1, 32, 32)  # (batch_size, channels, height, width)\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3da2f7",
   "metadata": {},
   "source": [
    "`tensorboard --logdir=src/T03_cnn_simple/runs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a25d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100  # number of epochs to run\n",
    "batch_size = 10  # size of each batch\n",
    "validation_interval = 4  # Evaluate every 10 epochs\n",
    "log_name = \"C1\"\n",
    "\n",
    "# Save/load\n",
    "cph = CheckpointHandler()\n",
    "cph.make_dir(\"./checkpoints\")\n",
    "if NEW_RUN:\n",
    "    dt = cph.get_dt()\n",
    "    log_dir = f\"runs/{dt}\"\n",
    "    save_path = f\"./checkpoints/{dt}.pth\"\n",
    "    epoch_start = 0\n",
    "else:\n",
    "    log_dir = f\"runs/{DT_REF}\"\n",
    "    load_path = f\"./checkpoints/{DT_REF}.pth\"\n",
    "    save_path = load_path\n",
    "    model, optimizer, epoch, val_loss = cph.load(\n",
    "        load_path=load_path, model=model, optimizer=optimizer\n",
    "    )\n",
    "    epoch_start = epoch\n",
    "    print(f\"Resuming from epoch: {epoch_start}\")\n",
    "\n",
    "epoch_end = epoch_start + n_epochs\n",
    "\n",
    "# Initialize Components\n",
    "early_stopper = EarlyStopper(patience=5)\n",
    "writer = SummaryWriter(log_dir=log_dir, purge_step=epoch_start)\n",
    "\n",
    "# Data\n",
    "data_handler.split_and_scale(test_size=0.2, val_size=0.1, random_state=RANDOM_STATE)\n",
    "ds_train = data_handler.get_train()\n",
    "ds_val = data_handler.get_val()\n",
    "loader_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Main loop\n",
    "for epoch in tqdm(\n",
    "    range(epoch_start, epoch_end), initial=epoch_start, desc=\"Epoch\", total=n_epochs\n",
    "):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_train_f1 = 0.0\n",
    "    logit_arr = []\n",
    "    label_arr = []\n",
    "\n",
    "    for X_batch, Y_batch in loader_train:\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_batch)\n",
    "        loss = loss_fn(Y_pred, Y_batch.view(-1))\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Multiplies the average loss per sample by the number of\n",
    "        # samples in the batch to get the total loss for this batch.\n",
    "        epoch_train_loss += loss.item() * X_batch.size(0)\n",
    "        logit_arr.append(Y_pred)\n",
    "        label_arr.append(Y_batch)\n",
    "\n",
    "    avg_train_loss = epoch_train_loss / len(loader_train.dataset)\n",
    "\n",
    "    logits = torch.concat(logit_arr, dim=0)\n",
    "    labels = torch.concat(label_arr, dim=0)\n",
    "    metrices, _, _ = calc_metrices(logits=logits, labels=labels.view(-1))\n",
    "    avg_train_f1 = metrices[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "    # Validation Phase\n",
    "    if epoch % validation_interval == 0 or epoch == epoch_start:\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        logit_arr = []\n",
    "        label_arr = []\n",
    "        with torch.no_grad():\n",
    "            for X_val, Y_val in loader_val:\n",
    "                Y_pred = model(X_val)\n",
    "                val_loss += loss_fn(Y_pred, Y_val.view(-1)).item() * X_val.size(0)\n",
    "                logit_arr.append(Y_pred)\n",
    "                label_arr.append(Y_val)\n",
    "\n",
    "        avg_val_loss = val_loss / len(loader_val.dataset)\n",
    "\n",
    "        logits = torch.concat(logit_arr, dim=0)\n",
    "        labels = torch.concat(label_arr, dim=0)\n",
    "        metrices, _, _ = calc_metrices(logits=logits, labels=labels.view(-1))\n",
    "        avg_val_f1 = metrices[\"weighted avg\"][\"f1-score\"]\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Early Stopping and Checkpoint\n",
    "        es = early_stopper(avg_val_loss)\n",
    "        if es[\"best_loss\"]:\n",
    "            cph.save(\n",
    "                save_path=save_path,\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                val_loss=avg_val_loss,\n",
    "                epoch=epoch,\n",
    "            )\n",
    "            print(\"Save model @ epoch:\", epoch)\n",
    "        if es[\"early_stop\"]:\n",
    "            print(\"Stopped at epoch:\", epoch)\n",
    "            break\n",
    "\n",
    "    writer.add_scalars(\n",
    "        log_name, {\"loss/train\": avg_train_loss, \"loss/val\": avg_val_loss}, epoch\n",
    "    )\n",
    "    writer.add_scalars(\n",
    "        log_name, {\"f1/train\": avg_train_f1, \"f1/val\": avg_val_f1}, epoch\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val, Y_val = ds_val[:]\n",
    "    test_pred = model(X_val)\n",
    "    final_loss = loss_fn(test_pred, Y_val.view(-1))\n",
    "    print(f\"Val loss: {final_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247ca046",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices, Y_pred_labels, Y_true_labels = calc_metrices(\n",
    "    logits=test_pred, labels=Y_val.view(-1), isPrint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassification\n",
    "loc = Y_pred_labels != Y_true_labels\n",
    "print(f\"Missclassification: {loc.sum()} out of {loc.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes2D = plt.subplots(3, 5, figsize=(12, 8))\n",
    "axes = list(itertools.chain.from_iterable(axes2D))  # Flatten 2D list\n",
    "X_val_miss = X_val[loc]\n",
    "Y_val_miss = Y_true_labels[loc]\n",
    "Y_pred_miss = Y_pred_labels[loc]\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx < loc.sum():\n",
    "        ax.imshow(X_val_miss[idx].view(28, 28), cmap=\"gray\")\n",
    "        ax.set_title(f\"True={Y_val_miss[idx]}, Pred={Y_pred_miss[idx]}\")\n",
    "    else:\n",
    "        ax.axis(\"off\")  # Hide unused axes\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
